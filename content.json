{"meta":{"title":"Peachey Blog","subtitle":null,"description":null,"author":"Peachey","url":"peachey.blog"},"pages":[],"posts":[{"title":"Dubbo协议与Hessian序列化","slug":"dubbo-hessian","date":"2018-05-04T14:55:33.000Z","updated":"2018-05-04T14:56:58.000Z","comments":true,"path":"2018/05/04/dubbo-hessian/","link":"","permalink":"peachey.blog/2018/05/04/dubbo-hessian/","excerpt":"","text":"","categories":[{"name":"Java","slug":"Java","permalink":"peachey.blog/categories/Java/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"peachey.blog/tags/Dubbo/"}]},{"title":"Innodb索引原理","slug":"innodb-index","date":"2018-03-21T14:41:25.000Z","updated":"2018-05-04T14:53:55.000Z","comments":true,"path":"2018/03/21/innodb-index/","link":"","permalink":"peachey.blog/2018/03/21/innodb-index/","excerpt":"","text":"Innodb是Mysql最常用的存储引擎，了解Innodb存储引擎的索引对于日常工作有很大的益处，索引的存在便是为了加速数据库行记录的检索。以下是我对最近学习的知识的一些总结，以及对碰到的以及别人提到过的问题的一些分析，如有错误，请指正，我会及时更正。 目录 Innodb表结构 B树与B+树 聚簇索引和二级索引 sql执行顺序 sql优化建议 一些问题分析 参考资料 1. Innodb表结构 此小结与索引其实没有太多的关联，但是为了便于理解索引的内容，添加此小结作为铺垫知识。 1.1 Innodb逻辑存储结构Mysql表中的所有数据被存储在一个空间内，称之为表空间，表空间内部又可以分为段(segment)、区(extent)、页(page)、行(row),逻辑结构如下图： 段(segment) 表空间是由不同的段组成的，常见的段有：数据段，索引段，回滚段等等，在Mysql中，数据是按照B+树来存储，因此数据即索引，因此数据段即为B+树的叶子节点，索引段为B+树的非叶子节点,回滚段用于存储undo日志，用于事务失败后数据回滚以及在事务未提交之前通过undo日志获取之前版本的数据，在Innodb1.1版本之前一个Innodb,只支持一个回滚段，支持1023个并发修改事务同时进行，在Innodb1.2版本，将回滚段数量提高到了128个，也就是说可以同时进行128*1023个并发修改事务。 区(extent) 区是由连续页组成的空间，每个区的固定大小为1MB,为保证区中页的连续性，Innodb会一次从磁盘中申请4~5个区，在默认不压缩的情况下，一个区可以容纳64个连续的页。但是在开始新建表的时候，空表的默认大小为96KB,是由于为了高效的利用磁盘空间，在开始插入数据时表会先利用32个页大小的碎片页来存储数据，当这些碎片使用完后，表大小才会按照MB倍数来增加。 页(page) 页是Innodb存储引擎的最小管理单位，每页大小默认是16KB，从Innodb 1.2.x版本开始，可以利用innodb_page_size来改变页size，但是改变只能在初始化Innodb实例前进行修改，之后便无法进行修改，除非mysqldump导出创建新库，常见的页类型有：数据页、undo页、系统页、事务数据页、插入缓冲位图页、插入缓冲空闲列表页、未压缩的二进制大对象页、压缩的二进制大对象页。 行(row) 行对应的是表中的行记录，每页存储最多的行记录也是有硬性规定的最多16KB/2-200,即7992行（16KB是页大小，我也不明白为什么要这么算,据说是内核定义） 1.2 Innodb行记录格式 Innodb提供了两种格式来存储行记录：Redundant格式、Compact格式、Dynamic格式、Compressed格式，Redudant格式是为了兼容保留的。 Redundant行格式（5.0版本之前的格式） 字段长度偏移列表：存储字段偏移量，与列字段顺序相反存放，若列长度小于255字节，用一个字节表示，若大于255字节，用两个字节表示 记录头信息：固定用6字节表示，具体含义如下： 隐藏列：事务id和回滚列id,分别占用6、7字节，若此表没有主键，还会增加6字节的rowid列。 Compact行格式(5.6版本的默认行格式) 变长字段长度列表：此字段标识列字段的长度，与列字段顺序相反存放，若列长度小于255字节，用一个字节表示，若大于255字节，用两个字节表示，这也是Mysql的VARCHAR类型最大长度限制为65535 NULL标志位：标识改列是否有空字段，有用1表示，否则为0，该标志位长度为ceil(N/8)（此处是Mysql技术内幕-Innodb存储引擎与官方文档有出入的地方）； 记录头信息：固定用5字节表示，具体含义如下： 列数据：此行存储着列字段数据，Null是不占存储空间的； 隐藏列：事务id和回滚列id,分别占用6、7字节，若此表没有主键，还会增加6字节的rowid列。 Note:关于行溢出，即Redundant格式、Compact格式存储很长的字符串，在该字段会存储该字符串的前768个字节的前缀（字段超过768字节则为变长字段），并将整个字符串存储在uncompress blob页中。 Dynamic格式(5.7版本默认行格式)和Compressed格式Dynamic格式和Compressed格式与Compact的不同之处在于对于行溢出只会在该列处存放20字节的指针，指向该字符串的实际存储位置，不会存储768字节前缀，而且Compressed格式在存储BLOB、TEXT、VARCHAR等类型会利用zlib算法进行压缩，能够以很高的存储效率来存储字符串。 1.3 Innodb数据页结构《Mysql技术内幕-Innodb存储引擎》书中对此有描述，但是应该不是太准确，书中有如下描述，此处不做详细介绍，若有兴趣请看此神书。 2. B树与B+树 B树与B+树通常用于数据库和操作系统的文件系统中。NTFS, ReiserFS, NSS, XFS, JFS, ReFS 和BFS等文件系统都在使用B+树作为元数据索引。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。 2.1 B树定义：B树（B-TREE）满足如下条件，即可称之为m阶B树： 每个节点之多拥有m棵子树； 根结点至少拥有两颗子树（存在子树的情况下); 除了根结点以外，其余每个分支结点至少拥有 m/2 棵子树； 所有的叶结点都在同一层上； 有 k 棵子树的分支结点则存在 k-1 个关键码，关键码按照递增次序进行排列； 关键字数量需要满足ceil(m/2)-1 &lt;= n &lt;= m-1； B树插入 B树删除 2.2 B+树定义：B+树满足如下条件，即可称之为m阶B+树： 根结点只有一个，分支数量范围为[2，m] 分支结点，每个结点包含分支数范围为[ceil(m/2), m]； 分支结点的关键字数量等于其子分支的数量减一，关键字的数量范围为[ceil(m/2)-1, m-1]，关键字顺序递增； 所有叶子结点都在同一层； 插入：B+树的插入必须保证插入后叶节点中的记录依然排序，同时需要考虑插入B+树的三种情况，每种情况都可能会导致不同的插入算法，插入算法入下图： 插入举例(未加入双向链表)： 1、 插入28这个键值，发现当前Leaf Page和Index Page都没有满，直接插入。 2、 插入70这个键值，Leaf Page已经满了，但是Index Page还没有满，根据中间的值60拆分叶节点。 3、 插入记录95，Leaf Page和Index Page都满了，这时需要做两次拆分 4、 B+树总是会保持平衡。但是为了保持平衡，对于新插入的键值可能需要做大量的拆分页（split）操作，而B+树主要用于磁盘，因此页的拆分意味着磁盘数据移动，应该在可能的情况下尽量减少页的拆分。因此，B+树提供了旋转（rotation）的功能。旋转发生在Leaf Page已经满了、但是其左右兄弟节点没有满的情况下。这时B+树并不会急于去做拆分页的操作，而是将记录移到所在页的兄弟节点上。通常情况下，左兄弟被首先检查用来做旋转操作，在第一张图情况下，插入键值70，其实B+树并不会急于去拆分叶节点，而是做旋转，50，55，55旋转。 删除：B+树使用填充因子（fill factor）来控制树的删除变化，50%是填充因子可设的最小值。B+树的删除操作同样必须保证删除后叶节点中的记录依然排序，同插入一样，B+树的删除操作同样需要考虑下图所示的三种情况，与插入不同的是，删除根据填充因子的变化来衡量。 删除示例(未加入双向链表)：1、删除键值为70的这条记录，直接删除（在插入第三点基础上的图）。 2、接着我们删除键值为25的记录，该值还是Index Page中的值，因此在删除Leaf Page中25的值后，还应将25的右兄弟节点的28更新到Page Index中。 3、删除键值为60的情况，删除Leaf Page中键值为60的记录后，填充因子小于50%，这时需要做合并操作，同样，在删除Index Page中相关记录后需要做Index Page的合并操作。 B树与B+树区别：以m阶树为例： 关键字不同：B+树中分支结点有m个关键字，其叶子结点也有m个，但是B树虽然也有m个子结点，但是其只拥有m-1个关键字。 存储位置不同：B+树非叶子节点的关键字只起到索引作用，实际的关键字存储在叶子节点，B树的非叶子节点也存储关键字。 分支构造不同：B+树的分支结点仅仅存储着关键字信息和儿子的指针，也就是说内部结点仅仅包含着索引信息。 查询不同（稳定）：B树在找到具体的数值以后，则结束，而B+树则需要通过索引找到叶子结点中的数据才结束，也就是说B+树的搜索过程中走了一条从根结点到叶子结点的路径。 3. 聚簇索引和二级索引3.1 聚簇索引每个Innodb的表都拥有一个索引，称之为聚簇索引，此索引中存储着行记录，一般来说，聚簇索引是根据主键生成的。为了能够获得高性能的查询、插入和其他数据库操作，理解Innodb聚簇索引是很有必要的。 聚簇索引按照如下规则创建： 当定义了主键后，innodb会利用主键来生成其聚簇索引； 如果没有主键，innodb会选择一个非空的唯一索引来创建聚簇索引； 如果这也没有，Innodb会隐式的创建一个自增的列来作为聚簇索引。 Note:对于选择唯一索引的顺序是按照定义唯一索引的顺序，而非表中列的顺序, 同时选中的唯一索引字段会充当为主键，或者Innodb隐式创建的自增列也可以看做主键。 聚簇索引整体是一个b+树，非叶子节点存放的是键值，叶子节点存放的是行数据，称之为数据页，这就决定了表中的数据也是聚簇索引中的一部分，数据页之间是通过一个双向链表来链接的，上文说到B+树是一棵平衡查找树，也就是聚簇索引的数据存储是有序的，但是这个是逻辑上的有序，但是在实际在数据的物理存储上是，因为数据页之间是通过双向链表来连接，假如物理存储是顺序的话，那维护聚簇索引的成本非常的高。 3.2 辅助索引除了聚簇索引之外的索引都可以称之为辅助索引，与聚簇索引的区别在于辅助索引的叶子节点中存放的是主键的键值。一张表可以存在多个辅助索引，但是只能有一个聚簇索引，通过辅助索引来查找对应的航记录的话，需要进行两步，第一步通过辅助索引来确定对应的主键，第二步通过相应的主键值在聚簇索引中查询到对应的行记录，也就是进行两次B+树搜索。相反通过辅助索引来查询主键的话，遍历一次辅助索引就可以确定主键了，也就是所谓的索引覆盖，不用回表（查询聚簇索引）。 创建辅助索引，可以创建单列的索引，也就是用一个字段来创建索引，也可以用多个字段来创建副主索引称为联合索引，创建联合索引后，B+树的节点存储的键值数量不是1个，而是多个，如下图： 联合索引的B+树和单键辅助索引的B+树是一样的，键值都是排序的，通过叶子节点可以逻辑顺序的读出所有的数据，比如上图所存储的数据时，按照(a,b)这种形式(1,1),(1,2),(2,1),(2,4),(3,1),(3,2)进行存放，这样有个好处存放的数据时排了序的，当进行order by对某个字段进行排序时，可以减少复杂度，加速进行查询； 当用select * from table where a=? and ?可以使用索引(a,b)来加速查询，但是在查询时有一个原则，sql的where条件的顺序必须和二级索引一致，而且还遵循索引最左原则，select * from table where b=?则无法利用(a,b)索引来加速查询。 辅助索引还有一个概念便是索引覆盖，索引覆盖的一个好处便是辅助索引不高含行记录，因此其大小远远小于聚簇索引，利用辅助索引进行查询可以减少大量的io操作。 4. sql执行顺序 以下的每一步操作都会生成一个虚拟表，作为下一个处理的输入，在这个过程中，这些虚拟表对于用户都是透明的，只用最后一步执行完的虚拟表返回给用户，在处理过程中，没有的步骤会直接跳过。 以下为逻辑上的执行顺序： (1) from：对左表left-table和右表right-table执行笛卡尔积(a*b)，形成虚拟表VT1; (2) on: 对虚拟表VT1进行on条件进行筛选，只有符合条件的记录才会插入到虚拟表VT2中; (3) join: 指定out join会将未匹配行添加到VT2产生VT3,若有多张表，则会重复(1)~(3); (4) where: 对VT3进行条件过滤，形成VT4, where条件是从左向右执行的; (5) group by: 对VT4进行分组操作得到VT5; (6) cube | rollup: 对VT5进行cube | rollup操作得到VT6; (7) having: 对VT6进行过滤得到VT7; (8) select: 执行选择操作得到VT8，本人看来VT7和VT8应该是一样的; (9) distinct: 对VT8进行去重，得到VT9; (10) order by: 对VT9进行排序，得到VT10; (11) limit: 对记录进行截取，得到VT11返回给用户。 Note:on条件应用于连表过滤，where应用于on过滤后的结果（有on的话），having应用于分组过滤 5. sql优化建议 索引有如下有点：减少服务器扫描的数据量、避免排序和临时表、将随机I/O变为顺序I/O。 可使用B+树索引的查询方式 全值匹配：与索引中的所有列进行匹配，也就是条件字段与联合索引的字段个数与顺序相同； 匹配最左前缀：只使用联合索引的前几个字段； 匹配列前缀：比如like &#39;xx%&#39;可以走索引； 匹配范围值：范围查询，比如&gt;,like等； 匹配某一列并范围匹配另外一列：精确查找+范围查找； 只访问索引查询：索引覆盖，select的字段为主键； 范围查询后的条件不会走索引，具体原因会在下一节进行介绍。 列的选择性（区分度）选择性（区分度）是指不重复的列值个数/列值的总个数，一般意义上建索引的字段要区分度高，而且在建联合索引的时候区分度高的列字段要放在前边，这样可以在第一个条件就过滤掉大量的数据，有利用性能的提升，对于如何计算列的区分度，有如下两种方法： 根据定义，手动计算列的区分度，不重复的列值个数/列值的总个数 通过mysql的carlinality,通过命令show index from &lt;table_name&gt;来查看解释一下此处的carlinality并不是准确值，而且mysql在B+树种选择了8个数据页来抽样统计的值，也就是说carlinality=每个数据页记录总和/8*所有的数据页，因此也说明这个值是不准确的，因为在插入/更新记录时，实时的去更新carlinality对于Mysql的负载是很高的，如果数据量很大的话，触发mysql重新统计该值得条件是当表中的1/16数据发生变化时。 但是选择区分度高的列作为索引也不是百试百灵的，某些情况还是不合适的，下节会进行介绍。 Mysql查询过程 当希望Mysql能够高性能运行的时候，最好的办法就是明白Mysql是如何优化和执行的，一旦理解了这一点，很多查询优化工作实际上就是遵循了一些原则让优化器能够按照预想的合理的方式运行————《引用自高性能Mysql》 当想Mysql实例发送一个请求时，Mysql按照如下图的方式进行查询： 客户端先发送一条查询给服务器； 服务器先检查查询缓存，如果命中了缓存，则立刻返回给存储在缓存中的结果，否则进入下一个阶段； 服务器端进行sql解析、预处理，再由优化器生成对应的执行计划； Mysql根据优化器生成的执行计划，调用存储引擎的API来执行查询 将结果返回客户端 注意&amp;建议 主键推荐使用整型，避免索引分裂； 查询使用索引覆盖能够提升很大的性能，因为避免了回表查询； 选择合适的顺序建立索引，有的场景并非区分度越高的列字段放在前边越好，联合索引使用居多； 合理使用in操作将范围查询转换成多个等值查询； in操作相当于多个等值操作，但是要注意的是对于order by来说，这相当于范围查询，因此例如select * from t1 where c1 in (x,x) order by c2的sql是不走索引的； 将大批量数据查询任务分解为分批查询； 将复杂查询转换为简单查询； 合理使用inner join,比如说分页时候 6. 一些问题分析 这个部分是我在学习过程中产生的一些疑问，以及在工作中碰到的或者同事提起的一些问题，对此我做了些调研，总结了一下并添加了些自己的理解，如有错误还请指正。 索引分裂此处提一下索引分裂，就我个人理解，在Mysql插入记录的同时会更新配置的相应索引文件，根据以上的了解，在插入索引时，可能会存在索引的页的分裂，因此会导致磁盘数据的移动。当插入的主键是随机字符串时，每次插入不会是在B+树的最后插入，每次插入位置都是随机的，每次都可能导致数据页的移动，而且字符串的存储空间占用也很大，这样重建索引不仅仅效率低而且Mysql的负载也会很高，同时还会导致大量的磁盘碎片，磁盘碎片多了也会对查询造成一定的性能开销，因为存储位置不连续导致更多的磁盘I/O,这就是为什么推荐定义主键为递增整型的一个原因，Mysql索引页默认大小是16KB，当有新纪录插入的时候，Mysql会留下每页空间的1/16用于未来索引记录增长，避免过多的磁盘数据移动。 自增主键的弊端对于高并发的场景，在Innodb中按照主键的顺序插入可能会造成明显的争用，主键的上界会成为“热点”，因为所有的插入都发生在此处，索引并发的插入可能会造成间隙锁竞争，何为间隙锁竞争，下个会详细介绍；另外一个原因可能是Auto_increment的锁机制，在Mysql处理自增主键时，当innodb_autoinc_lock_mode为0或1时，在不知道插入有多少行时，比如insert t1 xx select xx from t2，对于这个statement的执行会进行锁表，只有这个statement执行完以后才会释放锁，然后别的插入才能够继续执行，,但是在innodb_autoinc_lock_mode=2时，这种情况不会存在表锁，但是只能保证所有并发执行的statement插入的记录是唯一并且自增的，但是每个statement做的多行插入之间是不连接的。 优化器不使用索引选择全表扫描比如一张order表中有联合索引(order_id, goods_id)，在此例子上来说明这个问题是从两个方面来说： 查询字段在索引中 select order_id from order where order_id &gt; 1000,如果查看其执行计划的话，发现是用use index condition,走的是索引覆盖 查询字段不在索引中 select * from order where order_id &gt; 1000, 此条语句查询的是该表所有字段，有一部分字段并未在此联合索引中，因此走联合索引查询会走两步，首先通过联合索引确定符合条件的主键id,然后利用这些主键id再去聚簇索引中去查询，然后得到所有记录，利用主键id在聚簇索引中查询记录的过程是无序的，在磁盘上就变成了离散读取的操作，假如当读取的记录很多时（一般是整个表的20%左右），这个时候优化器会选择直接使用聚簇索引，也就是扫全表，因为顺序读取要快于离散读取，这也就是为何一般不用区分度不大的字段单独做索引，注意是单独因为利用此字段查出来的数据会很多，有很大概率走全表扫描。 范围查询之后的条件不走索引根据Mysql的查询原理的话，当处理到where的范围查询条件后，会将查询到的行全部返回到服务器端（查询执行引擎），接下来的条件操作在服务器端进行处理，这也就是为什么范围条件不走索引的原因了，因为之后的条件过滤已经不在存储引擎完成了。但是在Mysql 5.6以后假如了一个新的功能index condition pushdown(ICP),这个功能允许范围查询条件之后的条件继续走索引，但是需要有几个前提条件： 查询条件的第一个条件需要时有边界的，比如select * from xx where c1=x and c2&gt;x and c3&lt;x,这样c3是可以走到索引的； 支持InnoDB和MyISAM存储引擎； where条件的字段需要在索引中； 分表ICP功能5.7开始支持； 使用索引覆盖时，ICP不起作用。 set @@optimizer_switch = &quot;index_condition_pushdown=on&quot; 开启ICPset @@optimizer_switch = &quot;index_condition_pushdown=off&quot; 关闭ICP 范围查询统计函数不遵循Mysql索引最左原则比如创建一个表：1234567create table `person`( `id` int not null auto_increment primary key, `uid` int not null, `name` varchar(60) not null, `time` date not null, key `idx_uid_date` (uid, time) )engine=innodb default charset=utf8mb4; 当执行select count(*) from person where time &gt; &#39;2018-03-11&#39; and time &lt; ‘2018-03-16’时，time是可以用到idx_uid_date`的索引的,看如下的执行计划： 其中extra标识use index说明是走索引覆盖的，一般意义来说是Mysql是无法支持松散索引的，但是对于统计函数，是可以使用索引覆盖的，因此Mysql的优化器选择利用该索引。 分页offset值很大性能问题在Mysql中，分页当offset值很大的时候，性能会非常的差，比如limit 100000, 20，需要查询100020条数据，然后取20条，抛弃前100000条，在这个过程中产生了大量的随机I/O,这是性能很差的原因，为了解决这个问题，切入点便是减少无用数据的查询，减少随机I/O。解决的方法是利用索引覆盖，也就是扫描索引得到id然后再从聚簇索引中查询行记录，我知道有两种方式： 比如从表t1中分页查询limit 1000000,5 利用inner join select * from t1 inner join (select id from t1 where xxx order by xx limit 1000000,5) as t2 using(id),子查询先走索引覆盖查得id,然后根据得到的id直接取5条得数据。 利用范围查询条件来限制取出的数据 select * from t1 where id &gt; 1000000 order by id limit 0, 5，即利用条件id &gt; 1000000在扫描索引是跳过1000000条记录，然后取5条即可,这种处理方式的offset值便成为0了，但此种方式通常分页不能用，但是可以用来分批取数据。 索引合并1234SELECT * FROM tbl_name WHERE key1 = 10 OR key2 = 20;SELECT * FROM tbl_name WHERE (key1 = 10 OR key2 = 20) AND non_key=30;SELECT * FROM t1, t2 WHERE (t1.key1 IN (1,2) OR t1.key2 LIKE 'value%') AND t2.key1=t1.some_col;SELECT * FROM t1, t2 WHERE t1.key1=1 AND (t2.key1=t1.some_col OR t2.key2=t1.some_col2); 对于如上的sql在mysql 5.0版本之前，假如没有建立相应的联合索引，是要走全表扫描的，但是在Mysql 5.1后引入了一种优化策略为索引合并，可以在一定程度上利用表上的多个单列索引来定位指定行，其原理是将对每个索引的扫描结果做运算，总共有：交集、并集以及他们的组合，但是索引合并并非是一种合适的选择，因为在做索引合并时可能会消耗大量的cpu和内存资源，一般用到索引合并的情况也从侧面反映了该表的索引需要优化。 7. 参考资料 《Mysql技术内幕-Innodb存储引擎》：此书对于Innodb的讲解是比较全面而且细致的，但是稍微有一点点老并且还有一点点错误地方，此书是基于Mysql 5.6版本的，里边会混杂一些5.7的知识。 《MySQL技术内幕：SQL编程》：值得一看。 《高性能Mysql 第三版》：此书是一本Mysql神书，里边有很多的Mysql优化建议以及一些案例 官方文档：这个是比较权威而且是最新的文档，缺点是篇幅很长，内容很多，而且还是纯英文，在理解和阅读速度上相对而言没有中文来得快。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"peachey.blog/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"peachey.blog/tags/Mysql/"}]},{"title":"Shadowsocks原理详解","slug":"shadowsocks","date":"2017-12-28T14:37:56.000Z","updated":"2018-05-04T14:39:44.000Z","comments":true,"path":"2017/12/28/shadowsocks/","link":"","permalink":"peachey.blog/2017/12/28/shadowsocks/","excerpt":"","text":"Shadowsocks作为一个科学上网工具神器，它的出现极大的便利了Coder or else（本屌丝是这么认为的~）,此神器能够如此流行而又不倒自然是有原因的。Shadowsocks是一种基于Socks5代理方式的网络数据加密传输包，并采用Apache许可证、GPL、MIT许可证等多种自由软件许可协议开放源代码。shadowsocks分为服务器端和客户端，在使用之前，需要先将服务器端部署到服务器上面，然后通过客户端连接并创建本地代理。目前包使用Python、C、C++、C#、Go语言等编程语言开发。以下为本人根据看的各种资料以及略读源码总结而成，有的地方理解也不是很到位，如有错误还望指正。 目录 GFW简介（搜集于互联网） Socks 5协议原理 Shadowsocks工作原理 Shadowsocks部分源码分析 Shadowsocks使用 1. GFW简介（搜集于互联网） GFW为局外人起的绰号，英文Great Firewall of China, 正因为有这东西的存在，导致对外的网络受到其控制，成为了众所周知的“局域网”，这也是大部分翻墙软件的兴起缘由。 1）GFW的重要事件（简单列下，详细点击）： 1998年9月22日，全国公安工作信息化工程――”金盾工程”建设。 2002年9月3日，Google.com被封锁，主要手段为DNS劫持。 2002年9月12日，Google.com封锁解除，之后网页快照等功能被封锁，手段为TCP会话阻断。 2）GFW的主要技术手段 DNS污染/劫持在进行域名访问时，首先会将域名通过dns解析为对应的真实IP，然后通过IP进行HTTP访问，所谓DNS攻击手段，即通过某种手段使得客户机发起DNS查询但得到的却是错误的IP，导致客户机无法正常访问。防火长城会在骨干网出口的53端口进行IDS入侵检测，检测到黑名单域名等，会伪装成域名服务器向客户机发送虚假的回应，由于DNS查询请求一般是基于UDP无连接传输层协议，该协议特征是无状态连接、不可靠传输，DNS查询会接收最先到达的请求，抛弃之后到达的请求，因此导致客户机被欺骗，请求被重定位到虚假IP。 IP封锁在客户机发送请求到服务器的过程中会经过一系列路由的转发，在路由器转发的过程中会根据路由表中存储的表项来决定下一跳的路由器或主机，选择的下一跳地址会根据路由协议来决定。早期使用的是ACL（访问控制列表）来进行IP黑名单限制，现在更高效的路由扩散技术来进行对特定的IP进行封锁。早期路由器都是采用静态路由协议，每一条路由需要进行人工来配置路由表项，或者配置一些策略，在决定路由转发，这时可以通过检测，对相应要封锁的IP配置一条错误的路由，将之牵引到一个不做任何操作的服务器（黑洞服务器），此服务器所要做的就是丢包，这样便无声息封锁掉了。动态路由协议的出现可以更高效的进行屏蔽，动态路由协议可以让路由器通过交换路由表信息来动态更新路由表，并通过寻址算法来决定最优化的路径。因此可以通过动态路由协议的路由重分发功能将错误的信息散播到整个网络，从而达到屏蔽目的。 IP/端口黑名单该手段可以结合上边提到的IP封锁技术，将封锁精确到具体的端口，使该IP的具体端口接收不到请求，从而达到更细粒度的封锁。经常被封锁的端口如下： SSH的TCP协议22端口 HTTP的80端口 PPTP类型VPN使用的TCP协议1723端口，L2TP类型VPN使用的UDP协议1701端口，IPSec类型VPN使用的UDP协议500端口和4500端口，OpenVPN默认使用的TCP协议和UDP协议的1194端口 TLS/SSL/HTTPS的TCP协议443端口 Squid Cache的TCP协议3128端口 无状态TCP连接重置TCP连接会有三次握手，此种攻击方式利用了该特点来进行攻击，gfw会对特定IP的所有数据包进行监控，会对特定黑名单动作进行监控（如TLS加密连接），当进行TCP连接时，会在TCP连接的第二部SYNC-ACK阶段，伪装成客户端和服务器同时向真实的客户端和服务器发送RESET重置，以很低的成本来达到切断双方连接的目的。与丢弃客户机的包相比，在丢包后客户机会不断的发起重试，这样会加重黑洞服务器的负担，利用TCP连接重置来断开连接，客户机也不必发送ACK来确认，这样成本就要低得多。 TCP协议关键字阻断该手段在无状态TCP连接重置手段之上，加入了关键字过滤功能，当协议的头部包含特定的关键字便对其连接进行重置，比如HTTP协议、ED2K协议等等。 深度包检测深度数据包检测（Deep packet inspection,DPI）是一种于应用层对网络上传递的数据进行侦测与处理的技术，被广泛用于入侵检测、流量分析及数据挖掘。就字面意思考虑，所谓“深度”是相对于普通的报文检测而言的——相较普通的报文检测，DPI可对报文内容和协议特征进行检测。基于必要的硬件设施、适宜的检测模型及相应的模式匹配算法，gfw能够精确且快速地从实时网络环境中判别出有悖于预期标准的可疑流量，并对此及时作出审查者所期望的应对措施。 2. SOCKS 5协议原理 SOCKS 5 是一种代理协议，位于应用层于传输层的一个中介层，具体说应该属于会话层。 与SOCKS 4对比： 比SOCKS 4具有更高的安全性，支持更多的加密方式； 支持UDP； 地址方面支持域名和IPV6； SOCKS工作在比HTTP代理更低的层次： SOCKS使用握手协议来通知代理软件其客户端试图进行的连接SOCKS，然后尽可能透明地进行操作，而常规代理可能会解释和重写报头； 同时SOCKS还支持反向代理。 1) SOCK5 工作原理(参考论文)首先大体说一下计算机网络的模型,有助于从总体上明白SOCKS工作原理，如下图 TCP/IP模型 应用层 传输层 网络层 链路层 OSI模型 应用层 展示层 会话层 传输层 网络层 数据链路层 物理层 上边两种模型，这是总所周知的两种计算机网络模型，TCP/IP模型的应用层对应OSI的前三层，网络接入层对应OSI的最后两层，计算机在进行网络连接，请求方会有一个数据封装的过程，接收方会有一个数据解封的过程，具体的流程如下：1234567891011 请求方 接收方应用层 --&gt; data data --&gt; 应用层 | | ∧ ∧ ∨ ∨ | |传输层 --&gt; segment segment --&gt; 传输层 | | ∧ ∧ ∨ ∨ | |网络层 --&gt; package package --&gt; 网络层 | | ∧ ∧ ∨ ∨ | |链路层 --&gt; frame &gt;&gt;传输&gt;&gt; frame --&gt; 链路层 data: 传输层接收的的所有数据，当然包含应用层的协议数据 segment:传输层接收到数据分片，加上TCP/UPD的协议头 package:传输层的分片加上IP头 frame:将IP包前后分别加上帧头与帧尾 SOCK5是属于TCP/IP模型中应用层的协议，因此从以上的网络连接过程，就可以理解基于SOCKS 5协议的请求由客户机到代理机的整个过程如下： 将用户数据添加SOCKS 5头部，发到传输层； 传输层将SOCKS 5协议数据分段，添加TCP/UDP协议数据发到网络层； 网络层将TCP/UDP协议数据添加IP协议头，发往链路层； 链路层添加帧头与尾，将数据封装成帧发往代理机。 2) 基于TCP的SOCKS 5I. SOCKS 5 协商 Note:这个协商其实就是确认客户端与服务端确定验证方式的一次交互。 Client发送身份/方法选择， 协议头格式： VER NMETHODS METHODS VER: 版本，SOCKS 5为0x05 NMETHODS: METHODS部分的长度 METHODS: 是客户端支持的认证方式列表，每个方法占1字节,目前支持如下： 0X00: 不需验证 0x01: GSSAPI 0x02: USERNAME/PASSWORD 0x03~0x7F: IANA分配 0x80~0xFE: 私人方法保留 0xFF: 不接受的方法，也就是未定义/错误 Note: 一般来说具体的实现应该实现GSSAPI与USERNAME/PASSWORD GSSAPI:通用安全服务应用程序层, 能够使程序员在编码过程中实现通用安全，具体来说就是不用针对特定平台、特定安全机制、特定的保护形式以及特定的传输协议去进行安全实现，也就是说程序支持GSSAPI就可以说该程序是满足网络安全的，比如说支持公钥加密形式。 IANA：互联网地址编码分配机构，1)域名。IANA管理DNS域名根和.int，.arpa域名以及IDN（国际化域名）资源.2)数字资源。IANA协调全球IP和AS（自治系统）号并将它们提供给各区域Internet注册机构。3)协议分配。IANA与各标准化组织一同管理协议编号系统。 Server选择方法，协议头格式： VER METHOD VER: 版本， SOCKS 5为0x05 METHOD : Server从Client发送过来的METHODS中选择的方法 Note:接着Client与Server进行具体方法的子协商，但是若Server选择的方法为0xFF, 则Client必须断开连接 II. SOCKS 5 数据传输Client请求，协议头格式: VER CMD RSV ATYP DST.ADDR DST.PROT VER: 协议版本，SOCKS 5为0x05 CMD: CMD是命令码 0x01 CONNECT请求 0x02 BIND请求 0x03 UDP转发 RSV: 0x00 保留字段 ATYP: 地址类型 0x01 IPV4 0x03 域名 0x04 IPV6 DST.ADDR: 目标地址(即想访问的地址) DST.PORT: 目标地址的端口 Note: 代理及会根据DST.ADDR与DST.PORT这两个字段来请求目标主机 关于CMD字段： CONNECT:是指TCP代理模式 BIND:指双向连接，比如FTP协议，一个连接用于发送命令指令，另外一个连接用于传输数据 UDP:指UDP代理模式 Server回应， 协议头格式： VER CMD RSV ATYP BND.ADDR BND.PORT VER: 版本， SOCKS 5为0x05 REP: 回应字段 0x00 成功 0x01 socks服务器错误 0x02 未允许的连接 0x03 网络不可达 0x04 主机不可达 0x05 连接拒绝 0x06 TTL过期 0x07 命令码不支持 0x08 地址类型不支持 0x09~0xFF 未分配 RSV: 0x00 保留字段 ATYP: 地址类型 0x01 IPV4 0x03 域名 0x04 IPV6 BND.ADDR: socks服务器绑定地址 BND.PORT: socks服务器绑定端口 Note:Client会根据BND.ADDR与BND.PORT这两个字段向代理Server发送请求保留字段必须设置为0x00 3) 基于UDP的SOCKS 5基于UDP的请求和响应头是一样的，唯一不同的是Client的请求地址和端口字段是BIND.ADDR和BIND.PORT，格式如下： RSV FRAG ATYP DST.ADDR/BIND.ADDR DST.PORT/BIND.PROT DATA RSV: 0x00 保留字段 FRAG:当前分片ID，0x00表示不分片 ATYP: 地址类型 0x01 IPV4 0x03 域名 0x04 IPV6 DST.ADDR/BIND.ADDR: 目标主机/绑定主机 DST.PORT/BIND.PORT: 目标端口/绑定端口 DATA: 用户数据 Note: 代理及会根据DST.ADDR与DST.PORT这两个字段来请求目标主机,Client会根据BND.ADDR与BND.PORT这两个字段向代理Server发送请求。 FRAG字段用于标识是否进行分片，如果进行分片，数值越大表示分片排序越靠后，如果值为0x00则表示不分片，也就是说分片的order是从1开始的，表示范围为1~127。如果分片的话，每个接收者必须实现一个用于重新组长的队列（REASSEMBLY QUEUE）和一个用于标识过期的计时器（REASSEMBLY TIMER）当有分片被丢弃时，队列应该重新初始化。 地址类型不同，每个UDP报文的大小应该有所限制，以下说明都是方法独立的，按每次来算： ATYP为0x01时，小于10个字节 ATYP为0x02时，小于262个字节 ATYP为0x03时，小于20个字节 3. Shadowsocks工作原理 终于说到Shadowsocks工作原理了，在说这个之前必须先介绍以下普通socks 5的工作原理，将之与Shadowsocks的“变异版”进行对比，就可以看出Shadowsocks处理的妙处了！！ 1) 普通Socks 5 工作原理普通的代理是直接应用Socks 5 协议进行交互，也就是说客户端便是你的主机，Socks 5的Server是远程的代理机，具体的工作模式如下：1Socks 5客户端 &lt;---Socks 5---&gt; Socks 5服务器 &lt;---正常请求---&gt; 目标主机 Socks 5客户端在与Socks 5服务器交互的整个过程是有可能暴露在整个互联网中的，因此很容易被监控到，根据协议特征也可以很容易识别出来，若采取普通的Socks 5代理方式的话，若用于翻墙去看外边的世界，这种方式很容易被墙，代理服务器的IP极容易被加入黑名单，也就导致此代理的寿终正寝，因此一种新的方式Shadowsocks出现了。 2) Shadowsocks Socks 5工作原理Shadowsocks的处理方式是将Socks 5客户端与Socks5服务器的连接提前，Socks5协议的交互完全是在本地进行的，在网络中传输的完全是利用加密算法加密后的密文，这就很好的进行了去特征化，使得传输的数据不是很容易的被特征识别，本人认为这是Shadowsocks的最大的创新了，具体的流程如下：1234567Socks 5客户端 &lt;---Socks 5---&gt; sslocal ∧ | 密文 | ∨ ssserver &lt;---正常请求---&gt; 目标主机 其它方面的处理都与普通代理一样，特殊之处将Socks 5服务器拆成了两个部分： 本地的sslocal：sslocal对于Socks 5客户端便是Socks 5服务器,对于Socks 5客户端是透明的，sslocal完成与Socks 5客户端所有的交互。 远程的ssserver：ssserver对于目标主机同样也是Socks 5服务器，对于目标主机是透明的，完成Socks 5服务器与目标主机的所有操作。 sslocal-ssserver:sslocal接收到Socks 5客户端发送的数据，会将数据加密，并将配置信息发送到ssserver，ssserver接收到配置信息进行权限验证，然后将数据进行解密，然后将明文发往目标主机；当目标主机响应ssserver，ssserver将接收到的数据进行解包，并将数据加密，发送到sslocal，sslocal接收到加密后的数据进行解密，再发送给Socks 5客户端，这就完成了一次交互。 Note:整个流程的关键部分都在内部完成，在网络中传输的都是加密后的密文，很巧妙。 4. Shadowsocks部分源码分析 接下来便是对Shadowsocks源码部分的分析，由于本人对Python不是很精通，同时也没有深入的去研读其代码，代码部分便是略读了一下，在此简单的介绍下其源码，当然要感谢@clowwindy大大。 1) 源码文件结构Shadowsocks有多中语言的版本，Python是原版，整个项目的代码不多，总共4000多行，因此整体看起来并不是很困难，有时间的同学可以仔细去看下，我下载的是2.9.1版本的代码。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798|-shadowsocks-2.9.1| |---- LICENSE| |-debian| | |---- shadowsocks.manpages| | |---- compat| | |---- install| | |---- sslocal.1| | |---- changelog| | |---- init.d| | |---- config.json| | |---- ssserver.1| | |-source| | | `---- format| | |---- docs| | |---- rules| | |---- copyright| | |---- control| | `---- shadowsocks.default| |---- Dockerfile| |---- CHANGES| |-tests| | |---- server-dnsserver.json| | |---- nose_plugin.py| | |---- coverage_server.py| | |---- graceful_cli.py| | |---- graceful_server.py| | |---- aes.json| | |---- server-multi-passwd-empty.json| | |-socksify| | | |---- socks.conf| | | `---- install.sh| | |---- jenkins.sh| | |---- aes-cfb8.json| | |---- test_udp_src.sh| | |---- gen_multiple_passwd.py| | |---- salsa20.json| | |---- test_graceful_restart.sh| | |---- test.py| | |---- client-multi-server-ip.json| | |---- setup_tc.sh| | |---- server-multi-passwd-performance.json| | |---- rc4-md5.json| | |---- test_command.sh| | |---- test_large_file.sh| | |---- chacha20.json| | |---- server-multi-passwd-table.json| | |---- table.json| | |-libsodium| | | `---- install.sh| | |---- ipv6.json| | |---- workers.json| | |---- graceful.json| | |---- chacha20-ietf.json| | |---- fastopen.json| | |---- salsa20-ctr.json| | |---- test_udp_src.py| | |---- server-multi-passwd.json| | |---- ipv6-client-side.json| | |---- rc4-md5-ota.json| | |---- test_daemon.sh| | |---- assert.sh| | |---- server-multi-passwd-client-side.json| | |---- aes-cfb1.json| | |---- server-multi-ports.json| | `---- aes-ctr.json| |---- MANIFEST.in| |-utils| | |-fail2ban| | | `---- shadowsocks.conf| | |---- README.md| | `---- autoban.py| |---- README.md| |---- setup.py| |---- .gitignore| |---- CONTRIBUTING.md| |---- README.rst| |---- .travis.yml| |-shadowsocks| | |---- encrypt.py| | |---- lru_cache.py| | |-crypto| | | |---- openssl.py| | | |---- util.py| | | |---- __init__.py| | | |---- rc4_md5.py| | | |---- sodium.py| | | `---- table.py| | |---- server.py| | |---- local.py| | |---- udprelay.py| | |---- shell.py| | |---- __init__.py| | |---- eventloop.py| | |---- tcprelay.py| | |---- common.py| | |---- manager.py| | |---- asyncdns.py| | `---- daemon.py Shadowsocks的主要代码都在shadowsocks目录下，其他目录提供了一下打包、测试和许可协议的内容，以下简单介绍一下各个文件的内容：123456789101112131415161718192021shadowsocks|---- encrypt.py 提供加密函数调用|---- lru_cache.py 实现LRU缓存，用于应对并发量比较大的状况|-crypto 加密功能包| |---- openssl.py：openssl库调用| |---- util.py：工具类| |---- __init__.py| |---- rc4_md5.py：rc4-md5加密| |---- sodium.py：sodium加密| `---- table.py |---- server.py：ssserver实现|---- local.py：sslocal实现|---- udprelay.py：udp代理方式实现|---- shell.py：shell命令实现|---- __init__.py|---- eventloop.py：事件循环|---- tcprelay.py：tcp代理方式实现|---- common.py：公用类|---- manager.py：管理事件处理、连接处理等等|---- asyncdns.py：异步dns解析`---- daemon.py：守护线程实现 2) 源码分析 接下来分析一下ss的主流程代码，在整体对ss的工作原理有一个深入的了解。 I. local &amp; serverlocal.py中的代码实现的是本地客户端的实现，代码很短，几十行，将日志等对主流程无用代码精简过后，如下：12345678910111213141516171819202122# 加载配置文件config = shell.get_config(True)# 是否运行为守护进程daemon.daemon_exec(config)# 创建异步dns查询对象dns_resolver = asyncdns.DNSResolver()# 创建tcp代理方式转发对象tcp_server = tcprelay.TCPRelay(config, dns_resolver, True)# 创建udp代理方式转发对象udp_server = udprelay.UDPRelay(config, dns_resolver, True)# 创建事件循环处理对象loop = eventloop.EventLoop()# 将dns查询、tcp代理方式转发、udp代理方式转发绑定到事件循环dns_resolver.add_to_loop(loop)tcp_server.add_to_loop(loop)udp_server.add_to_loop(loop)# 预设信号处理函数，接收到正常的退出信号signal.signal(getattr(signal, &apos;SIGQUIT&apos;, signal.SIGTERM), handler)# SIGINT是键盘ctrl+csignal.signal(signal.SIGINT, int_handler)# 开启事件循环loop.run() server.py和local.py的基本流程时差不多的，与local.py不同的地方需要对多个客户端连接过来的请求进行处理，因此会多一些流程，下面是精简过的代码：12345678910111213141516171819202122232425262728293031# 加载配置文件config = shell.get_config(False)# 是否运行为守护进程daemon.daemon_exec(config)# 创建异步dns查询对象dns_resolver = asyncdns.DNSResolver()# 添加tcp代理方式转发tcp_servers.append(tcprelay.TCPRelay(a_config, dns_resolver, False))# 添加udp代理方式转发udp_servers.append(udprelay.UDPRelay(a_config, dns_resolver, False))# 预设信号处理函数，接收到正常的退出信号signal.signal(getattr(signal, &apos;SIGQUIT&apos;, signal.SIGTERM),child_handler)# SIGINT是键盘ctrl+csignal.signal(signal.SIGINT, int_handler)# 创建事件循环处理对象loop = eventloop.EventLoop()# 将dns绑定到事件循环dns_resolver.add_to_loop(loop)# 实现多个线程处理def run_server(): ... loop = eventloop.EventLoop() dns_resolver.add_to_loop(loop) # 开启事件处理无限循环 loop.run() ...if int(config[&apos;workers&apos;]) &gt; 1: ... # 生成多个线程来处理，也就是配置的workerselse: run_server() II. udp &amp; tcpudprelay.py为UDP代理方式的实现，一下为精简后代码，抽取主要流程。123456789101112131415161718192021222324252627282930313233343536SOCKS5 UDP 请求+----+------+------+----------+----------+----------+|RSV | FRAG | ATYP | DST.ADDR | DST.PORT | DATA |+----+------+------+----------+----------+----------+| 2 | 1 | 1 | Variable | 2 | Variable |+----+------+------+----------+----------+----------+SOCKS5 UDP 响应+----+------+------+----------+----------+----------+|RSV | FRAG | ATYP | DST.ADDR | DST.PORT | DATA |+----+------+------+----------+----------+----------+| 2 | 1 | 1 | Variable | 2 | Variable |+----+------+------+----------+----------+----------+shadowsocks UDP 请求 (加密前)+------+----------+----------+----------+| ATYP | DST.ADDR | DST.PORT | DATA |+------+----------+----------+----------+| 1 | Variable | 2 | Variable |+------+----------+----------+----------+shadowsocks UDP 响应 (加密前)+------+----------+----------+----------+| ATYP | DST.ADDR | DST.PORT | DATA |+------+----------+----------+----------+| 1 | Variable | 2 | Variable |+------+----------+----------+----------+shadowsocks UDP 请求和响应 (加密后)+-------+--------------+| IV | PAYLOAD |+-------+--------------+| Fixed | Variable |+-------+--------------+命名：dest 目标主机local ss的本地serverremote ss的远程serverclient 向其他UDPserver发送请求的UDP clientsserver 处理用户请求的UDP server 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#构造函数，config为配置文件，dns_resolver为dns解析，is_local用于区分是local还是server，stat_callback为回调函数用于统计，在manager.py中有调用def __init__(self, config, dns_resolver, is_local, stat_callback=None): ... #全局参数声明、赋值 #创建socket、绑定端口、设置阻塞方式 server_socket = socket.socket(af, socktype, proto) server_socket.bind((self._listen_addr, self._listen_port)) server_socket.setblocking(False) ...# 获取服务器IP+端口def _get_a_server(self): ...# 关闭连接def _close_client(self, client): ...# 处理serverdef _handle_server(self): # 获取udp server server = self._server_socket # 接收数据 data, r_addr = server.recvfrom(BUF_SIZE) # 解密数据，如果是local的话，因为接收的是本地的数据，是不需要解密的 data, key, iv = encrypt.dencrypt_all(self._password,self._method,data) # 解析头 header_result = parse_header(data) addrtype, dest_addr, dest_port, header_length = header_result ... #如果是local需要将数据发送到remote,如果是remote需要将数据发送到dest if self._is_local: server_addr, server_port = self._get_a_server() else: server_addr, server_port = dest_addr, dest_port ... # 加密数据 data = encrypt.encrypt_all_m(key, iv, m, self._method, data) ... #发送 client.sendto(data, (server_addr, server_port))# 处理clientdef _handle_client(self, sock): # 接收数据 data, r_addr = sock.recvfrom(BUF_SIZE) ... # 加密数据 data = encrypt.encrypt_all(self._password, self._method, 0, data) ... # 获取地址 client_addr = self._client_fd_to_server_addr.get(sock.fileno()) ... # 发送 self._server_socket.sendto(response, client_addr)# 添加事件def add_to_loop(self, loop): ...# 处理事件def handle_event(self, sock, fd, event): # 区分处理client或server if sock == self._server_socket: self._handle_server() elif sock and (fd in self._sockets): self._handle_client(sock)# 周期性处理def handle_periodic(self): ...# 关闭UDP代理def close(self, next_tick=False): tcprelay.py 抽取主流程代理如下：1234567891011121314151617181920212223# 对于每个端口，有一个tcp relay,对于每个tcp relay# 对于每个连接，有一个tcp relay handler来处理# 对于每个handler，有两个socket,# - local 连接到client,# - remote 连接到远程主机（要访问的主机）# 对于每个handler可以有如下几个阶段：# sslocal# - stage 0 接收从本地的method请求，并返回选择信息# - stage 1 从本地接收请求地址，并进行dns解析# - stage 2 udp相关# - stage 3 dns解析完毕，连接远程主机# - stage 4 连接中，并接收本地发送的数据# - stage 5 远程主机连接成功，发送数据# ssserver# - stage 0 直接跳到阶段1# - stage 1 从本地接收请求地址，并进行dns解析# - stage 2 udp相关# - stage 3 dns解析完毕，连接远程主机# - stage 4 连接中，并接收本地发送的数据# - stage 5 远程主机连接成功，发送数据# 对于每个handler，有两个流方向：# upstream：client-&gt;server,读本地，写入远程主机# downstream：server-&gt;client,读远程主机，写入本地 12345678910111213141516171819202122232425262728293031# config为配置，dns_resolver为dns解析，is_local是否为client，stat_callback回调用于统计def __init__(self, config, dns_resolver, is_local, stat_callback=None): ... # 全局参数声明、赋值 # 创建socket、绑定端口、设置阻塞方式 server_socket = socket.socket(af, socktype, proto) server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) server_socket.bind(sa) server_socket.setblocking(False)...# 添加到事件循环def add_to_loop(self, loop): ...# 处理事件def handle_event(self, sock, fd, event): ... # 如果是server_socket 监听 if sock == self._server_socket: ... # 监听 conn = self._server_socket.accept() ... # 如果不是，进行事件处理 else: ... handler.handle_event(sock, event)# 周期性处理def handle_periodic(self): ...# 关闭TCP代理def close(self, next_tick=False): III. eventloopepoll模型（多路复用IO模型） Shadowsocks之前是采用多线程模式，一个连接来了应用一个线程处理，但是这种处理方式在并发量特别大的情况下，性能不是很理想，后来转用eventloop模型，基于epoll模型的一种封装，因此此处需要介绍一下epoll模型。 下边说的是linux下的epoll，epoll_create是创建epoll对象，epoll_ctrl是控制时间函数，比如添加、删除和修改事件等等，epoll_wait是用于返回IO事件，类似ss中的poll函数 在linux，一切皆文件．所以当调用epoll_create时，内核给这个epoll分配一个file，但是这个不是普通的文件，而是只服务于epoll． 所以当内核初始化epoll时，会开辟一块内核高速cache区，用于安置我们监听的socket，这些socket会以红黑树的形式保存在内核的cache里，以支持快速的查找，插入，删除．同时，建立了一盒list链表，用于存储准备就绪的事件．所以调用epoll_wait时，在timeout时间内，只是简单的观察这个list链表是否有数据，如果没有，则睡眠至超时时间到返回；如果有数据，则在超时时间到，拷贝至用户态events数组中． 那么，这个准备就绪list链表是怎么维护的呢？当我们执行epoll_ctl时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了。 epoll有两种模式LT(水平触发)和ET(边缘触发)，LT模式下，主要缓冲区数据一次没有处理完，那么下次epoll_wait返回时，还会返回这个句柄；而ET模式下，缓冲区数据一次没处理结束，那么下次是不会再通知了，只在第一次返回．所以在ET模式下，一般是通过while循环，一次性读完全部数据．epoll默认使用的是LT． epollloop.py:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 构造函数,ss支持epoll、kqueue、selectdef __init__(self): if hasattr(select, &apos;epoll&apos;): self._impl = select.epoll() model = &apos;epoll&apos; elif hasattr(select, &apos;kqueue&apos;): self._impl = KqueueLoop() model = &apos;kqueue&apos; elif hasattr(select, &apos;select&apos;): self._impl = SelectLoop() model = &apos;select&apos; ...# 获取事件def poll(self, timeout=None): events = self._impl.poll(timeout) return [(self._fdmap[fd][0], fd, event) for fd, event in events]# 添加时间def add(self, f, mode, handler): fd = f.fileno() self._fdmap[fd] = (f, handler) self._impl.register(fd, mode)# 移除事件def remove(self, f): fd = f.fileno() del self._fdmap[fd] self._impl.unregister(fd)# 定时添加def add_periodic(self, callback): self._periodic_callbacks.append(callback)# 周期性移除def remove_periodic(self, callback): self._periodic_callbacks.remove(callback)# 修改def modify(self, f, mode): fd = f.fileno() self._impl.modify(fd, mode)# 停止def stop(self): self._stopping = True# 运行函数def run(self): events = [] while not self._stopping: asap = False # epoll的系统调用，事件发生，poll调用返回。和select系统调用的关键区别 events = self.poll(TIMEOUT_PRECISION) ... # 循环处理事件 for sock, fd, event in events: handler = self._fdmap.get(fd, None) if handler is not None: handler = handler[1] try: handler.handle_event(sock, fd, event) except (OSError, IOError) as e: shell.print_exception(e) ... 5. Shadowsocks使用 这部分在网上一搜一大片，主要是先得有一个可以联通外边网站的服务器，然后在服务器上搭建ssserver,然后配置本地的sslocal，其实现在有很多的ui客户端，要比命令行好用的多,以下举例用ubuntu搭建ssserver。 I. ssserver搭建 更新软件源：sudo apt-get update 安装pip环境：sudo apt-get install python-pip 安装sserver：sudo pip install shadowsocks II. sserver配置 使用命令启动：sudo ssserver -p 8388 -k password -m aes-256-cfb -d start 使用配置文件：sudo ssserver -c /etc/shadowsocks.json -d start加上-d start可以让服务端在后台运行，停止改为stop即可配置文件： 123456789101112&#123; # 服务器IP &quot;server&quot;:&quot;my_server_ip&quot;, # 代理端口 &quot;server_port&quot;:8388, # 密码 &quot;password&quot;:&quot;mypassword&quot;, # 超时时间 &quot;timeout&quot;:300, # 加密方式 &quot;method&quot;:&quot;aes-256-cfb&quot;&#125; 配置开机启动编辑rc.local文件sudo vi /etc/rc.local在exit 0 这一行之前加入/usr/local/bin/ssserver –c /etc/shadowsocks.json 加速：可以选择kcptun、锐速、finalspeed等插件，kcptun简单粗暴而且免费。","categories":[{"name":"Python","slug":"Python","permalink":"peachey.blog/categories/Python/"}],"tags":[{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"peachey.blog/tags/Shadowsocks/"}]},{"title":"maven-introduction","slug":"maven-introduction","date":"2016-11-12T14:25:44.000Z","updated":"2018-05-04T14:28:19.000Z","comments":true,"path":"2016/11/12/maven-introduction/","link":"","permalink":"peachey.blog/2016/11/12/maven-introduction/","excerpt":"","text":"在业余时间对Maven的文档做了一个翻译，由于本人的水平有限，可能会有一些出入，欢迎指正。这个指南意欲为第一次使用Maven的人做参考，同时也是作为一个常见用例的指南。对于第一次使用的人，推荐按这个指南的步骤去学习，对于比较熟悉Maven的人来说，这个指南尽量为目前的需求提供一个快速的解决方案。以下的教程是假设读者已经下载Maven并将Maven本地安装的前提下，如果没有进行次步，请点击这个链接下载和安装下载并安装。好了，现在你应该已经安装了Maven,我们即将开始。在我们介绍例子之前，我们先会简介的介绍一下什么是Maven、Maven怎样帮助你做日常工作以及与团队协作。当然,Maven对于小项目很有效，但是Maven同样能够很有效的使团队成员聚焦于项目的更重要的部分，基础架构的建立完全可以交给Maven. 小结目录 什么是Maven？ Mavne如何使我的开发流程受益？ 我如何初始化Maven？ 我如何建立第一个Maven项目？ 我如何编译应用源码？ 我如何编译测试源码并且做单元测试？ 我如何创建一个jar文件并且将之安装到我的本地仓库？ 什么是SNAPSHOT版本？ 我如何使用插件？ 我如何将资源添加到jar文件当中？ 我如何过滤资源文件？ 我如何使用外部的依赖？ 我如何发布jar到远程仓库？ 我如何创建帮助文档？ 我如何构建其他类型的项目？ 我如何同时构建多个项目？ 什么是Maven？大致一看，Maven貌似有很多东西，但是简单来说，Maven是对于模型化创建项目基础结构的一种尝试，通过一种清晰的并且拥有最佳实践效果的目录来提高生产率和项目的可读性。Maven是一款项目管理和理解项目的工具，通过以下方式来管理项目： 构建 帮助文档 报告 依赖 软件配置管理 发行 发布如果你想知道更多关于Maven的背景知识，你可以查阅Maven的哲学以及Maven的历史。接下来开始讲述如何让用户受益于Maven。 Mavne如何使我的开发流程受益？Maven有助于你项目的构建过程，Maven通过使用标准约定和惯例来加速你的开发周期，同时有助于提高你的项目开发的成功率。现在我们概述了一些关于Maven的历史和目的，让我们通过几个实际的例子来帮助你使用Maven! 我如何初始化Maven？Maven的默认配置通常都很高效，但是如果你需要改变缓存位置，或通过HTTP代理使用Maven，你需要创建配置文件，具体请看Maven配置指南 我如何建立第一个Maven项目？我们将要开始创建你的第一个Maven项目！为了创建我们第一个Maven项目，我们需要利用Maven的archetype插件。archetype被定义为原始的类型或者模型，是从所有拥有相似成分的东西抽象出来的。在Maven中，archetype是一个项目模板，包含了一些针对用户需求生成的一些上线的Maven项目的特性。现在我们将要展示archetype插件如何工作，但是如果你想知道更多的关于archetype的信息，请看Archetypes介绍。开始创建你的第一个项目，为了创建最简单的Maven项目，请执行如下命令：1234mvn -B archetype:generate \\ -DarchetypeGroupId=org.apache.maven.archetypes \\ -DgroupId=com.mycompany.app \\ -DartifactId=my-app 一旦你执行了这条命令，你将会发现一些事情会发生。首先你会注意到一个名称为my-app的目录被创建为一个新的项目，冰鞋这个目录包含一个名称为pom.xml的文件，如下：1234567891011121314151617181920&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;Maven Quick Start Archetype&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; pom.xml包含此项目的项目对象模型(POM).POM是Maven的最小工作单元，这个很重要，需要记住，因为Maven所有的围绕关于项目概念的东西是项目式的，简单来说，POM包含了所有关于你的项目重要的信息片段，而且基本上是以一站式服务的形式来找到所有关于你的项目的的东西。明白POM是很重要的，新手推荐看一下POM简介。上边pom文件描述的是一个很简单的POM，但是仍然展现出了每个POM的关键元素，因此让我们通过他们来了解POM的要点： project:这是所有Maven的pom.xml的顶层元素 modelVersion:这个元素表明当前POM所使用什么版本的对象模型。这个版本号很少发生改变，为了确保使用的稳定性，这是强制的，有但也是很少就是当Maven开发人员觉得有必要改变模型的时候。 groupId:这个元素代表创建这个项目的组织或小组的唯一标识。这个groupId是一个项目的关键标识符，很典型的做法是基于你组织的经过完全认证的域名。比如org.apache.maven.plugins是所有Maven插件的指定groupId。 artifactId：这个元素代表着个项目生成的初级artifact的唯一基名。一个项目的初级artifact通常都是一个jar文件。二级artifacts比如源码包经常会使用artifactId作为他们最终名称的一部分。一个Mavne生成的典型的artifact应该有类似-.的命名模式。(例如myapp-1.0.jar) packaging:这个元素代表打包类型，比如jar,war,ear等等。这不仅意味artifact生成文件是jar,war或者ear，而且指出在构建过程中使用的特定的生命周期。(生命周期这个主题我们将会在指南的接下来进行讲述。现在，只需记住一个项目的打包类型可以在定制的构建生命周期当中发挥作用).packaging元素的默认值是jar，因此你在大多数项目中没有必要去指定。 version:这个元素代表项目生成的artifact的版本。Maven的版本管理对你大有帮助并且你经常在版本号中看到SNAPSHOT，这表明这个项目还处于开发的阶段，我们将会讨论snapshots的使用以及在本指南中其有何进一步功用。 name:这个元素代表项目的显示名称，经常在Maven生成文档的使用被用到。 description:这个元素提供了为你的项目提供了一个基本的描述。这个也经常在Maven生成文档时候被用到。对于适合在POM中使用的元素的完全参考，请参考POM参考，现在让我们返回到项目。在通过archetype生成你的第一个项目后，你会注意到如下的目录结构被创建了：123456789101112131415my-app|-- pom.xml`-- src |-- main | `-- java | `-- com | `-- mycompany | `-- app | `-- App.java `-- test `-- java `-- com `-- mycompany `-- app `-- AppTest.java 正如你看到的，这个项目拥有一个POM和一个你的应用源码的源码目录树以及一个你的测试代码的源码目录树。这个是Maven项目的标准布局(应用源码在${basedir}/src/main/java中，测试代码在${basedir}/src/test/java,${basedir}代表包含pom.xml文件的目录)。如果你准备创建一个maven项目，这中目录结构是我们推荐使用的。这是一个Maven的约定，想要了解更多，你可以阅读标准目录布局介绍。现在我们拥有一个POM，一些应用源码，一些测试代码，你有可能会问… 我如何编译应用源码？将目录改变到pom.xml所在的目录并且执行如下的命令来编译你的应用源码：1mvn compile 在执行了这条命令后你应该看到如下的输出：123456789101112131415161718192021[INFO] ----------------------------------------------------------------------------[INFO] Building Maven Quick Start Archetype[INFO] task-segment: [compile][INFO] ----------------------------------------------------------------------------[INFO] artifact org.apache.maven.plugins:maven-resources-plugin: \\ checking for updates from central...[INFO] artifact org.apache.maven.plugins:maven-compiler-plugin: \\ checking for updates from central...[INFO] [resources:resources]...[INFO] [compiler:compile]Compiling 1 source file to &lt;dir&gt;/my-app/target/classes[INFO] ----------------------------------------------------------------------------[INFO] BUILD SUCCESSFUL[INFO] ----------------------------------------------------------------------------[INFO] Total time: 3 minutes 54 seconds[INFO] Finished at: Fri Sep 23 15:48:34 GMT-05:00 2005[INFO] Final Memory: 2M/6M[INFO] ---------------------------------------------------------------------------- 第一次你执行这个命令，Maven将会下载执行此命令的所有的插件和相关的依赖。初始安装Maven，这个过程将会需要一段时间来完成(从上面的输出来看，这将会需要大约4分钟)。如果你再次执行这个命令，Maven会拥有它所有的需要的，因此它不会下载任何新的东西，并且会很快的执行这条命令。 正如你从输出中可以看到的，编译后的class文件将会被放在${basedir}/target/classes,这是Maven的另外一个通常的约定。因此，如果你的观察很敏锐，你会发现利用通常的约定，POM篇幅很小，你不用很明确的告诉Maven你的源码在哪里，应该向什么地方输出。通过利用通常的Maven约定，你花费很小的力气可以获得很多的便利！ 我如何编译测试源码并且做单元测试？现在你成功的编译了你的应用源码并且现在你需要做一些单元测试，这些测试代码需要编译和执行(因为每个程序员总是编写和执行他们的单元测试)执行 如下的命令：1mvn test 执行这条命令，你应该看到如下的输出：123456789101112131415161718192021222324252627282930313233[INFO] ----------------------------------------------------------------------------[INFO] Building Maven Quick Start Archetype[INFO] task-segment: [test][INFO] ----------------------------------------------------------------------------[INFO] artifact org.apache.maven.plugins:maven-surefire-plugin: \\ checking for updates from central...[INFO] [resources:resources][INFO] [compiler:compile][INFO] Nothing to compile - all classes are up to date[INFO] [resources:testResources][INFO] [compiler:testCompile]Compiling 1 source file to C:\\Test\\Maven2\\test\\my-app\\target\\test-classes...[INFO] [surefire:test][INFO] Setting reports dir: C:\\Test\\Maven2\\test\\my-app\\target/surefire-reports ------------------------------------------------------- T E S T S-------------------------------------------------------[surefire] Running com.mycompany.app.AppTest[surefire] Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0 sec Results :[surefire] Tests run: 1, Failures: 0, Errors: 0 [INFO] ----------------------------------------------------------------------------[INFO] BUILD SUCCESSFUL[INFO] ----------------------------------------------------------------------------[INFO] Total time: 15 seconds[INFO] Finished at: Thu Oct 06 08:12:17 MDT 2005[INFO] Final Memory: 2M/8M[INFO] ---------------------------------------------------------------------------- 一些需要注意的是：-Maven这次下载了更多的依赖，这些事执行测试需要的依赖和插件，但是对于已经存在的是不会下载的(本地仓库)-在编译和执行测试之前，Maven编译主要的代码(所有的class文件都是最新的，只要我们在编译以后不改变任何东西)如果你简单的想编译你的测试代码(并不去执行)，你可以执行如下命令：1mvn test-compile 现在你可以编译你的应用源码，编译你的测试代码，并且执行测试，你想继续下一步，你将会问… 我如何创建一个jar文件并且将之安装到我的本地仓库？创建一个jar文件很简单，执行如下命令就可以了：1mvn package 如果你看一下你项目的POM你就会发现packaging元素是被设置为jar的。这就是为什么Maven知道去生成一个jar文件的原因了。你查看一下${basedir}/target目录你就会看到生成的jar文件。现在你将想去安装你生成的artifact(jar文件)到你的本地仓库(${user.home/.m2/repository是默认位置)。想了解更到关于仓库的信息，你可以查看仓库介绍，接着让我们继续安装我们的artifact执行如下的命令：1mvn install 执行命令后你应该看到如下的输出：12345678910111213141516171819202122232425262728293031323334[INFO] ----------------------------------------------------------------------------[INFO] Building Maven Quick Start Archetype[INFO] task-segment: [install][INFO] ----------------------------------------------------------------------------[INFO] [resources:resources][INFO] [compiler:compile]Compiling 1 source file to &lt;dir&gt;/my-app/target/classes[INFO] [resources:testResources][INFO] [compiler:testCompile]Compiling 1 source file to &lt;dir&gt;/my-app/target/test-classes[INFO] [surefire:test][INFO] Setting reports dir: &lt;dir&gt;/my-app/target/surefire-reports ------------------------------------------------------- T E S T S-------------------------------------------------------[surefire] Running com.mycompany.app.AppTest[surefire] Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 0.001 sec Results :[surefire] Tests run: 1, Failures: 0, Errors: 0 [INFO] [jar:jar][INFO] Building jar: &lt;dir&gt;/my-app/target/my-app-1.0-SNAPSHOT.jar[INFO] [install:install][INFO] Installing &lt;dir&gt;/my-app/target/my-app-1.0-SNAPSHOT.jar to \\ &lt;local-repository&gt;/com/mycompany/app/my-app/1.0-SNAPSHOT/my-app-1.0-SNAPSHOT.jar[INFO] ----------------------------------------------------------------------------[INFO] BUILD SUCCESSFUL[INFO] ----------------------------------------------------------------------------[INFO] Total time: 5 seconds[INFO] Finished at: Tue Oct 04 13:20:32 GMT-05:00 2005[INFO] Final Memory: 3M/8M[INFO] ---------------------------------------------------------------------------- 注意surefire插件(用于执行测试)通过特定的文件命名约定去寻找测试代码。默认的命名规则如下：**/*Test.java**/Test*.java**/*TestCase.java但是默认的不包括如下：**/Abstract*Test.java**/Abstract*TestCase.java你已经走了初始化、构建、测试、打包和安装整个流程，这是Maven项目的典型过程。如果你已经注意的话，这就是大部分项目利用Maven来做的工作。所有你能够做的都在这个18行的文件中即项目模型或POM。如果你了解利用Ant创建相同功能的文件，你会发现篇幅一般是POM的两倍。Maven可以给你提供更多的功能而且不用更多的设置。利用Ant得到更多的功能，你必须注意各种容易错的条件。什么东西还是你可以免费得到的呢？这里有很多的Maven插件。我们这里提及一个插件，它是Maven的一个重要特性之一。POM中不用任何多余的设置，可以为你的项目生成一个站点。你可能会想去定制化你的Maven站点，但是假如你想很快为你的项目提供一个基本信息的介绍，那么可以执行如下的命令：1mvn site 这里也有很多独立的功能可以去执行，例如：1mvn clean 这个命令将会删除target目录和其中的所有构建数据，就类似开始的样子.可能你想为项目生成一个intellij idea的描述？1mvn idea:idea 这样就可以运行在IDEA中，这将会更新设置，而不是恢复成最开始的样子。如果你使用Eclipse IDE,只需：1mvn eclipse:eclipse 注意：许多类似的Maven1.0目标还存在，比如jar:jar,但是他们的结果可能和你所期望的是不一样的，现在jar:jar不会重新编译源码，它只会简单的利用target/classes来创建jar文件，会假设所有的东西在之前已经做了，比如说编译。 什么是SNAPSHOT版本？注意pom.xml中版本号的值会带有-SNAPSHOT的后缀。12345678&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; ... &lt;groupId&gt;...&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; ... &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;Maven Quick Start Archetype&lt;/name&gt; ... SNAPSHOT指开发分支的最新的代码，无法保证代码是稳定的或者不会改变的。相反的，release版本的代码是不会改变的。换句话说，SNAPSHOT版本是release之前的开发版本。在发布过程中，版本例如x.y-SNAPSHOT会变成x.y。发布过程经常会增量开发版本为x.(y+1)-SNAPSHOT。比如：版本号1.0-SNAPSHOT的发布版本为1.0,并且新的开发版本为1.1-SNAPSHOT。 我如何使用插件？无论何时你想去定制化你的Maven项目，所需做的就是添加或重新配置插件。Maven 1.0的用户请注意：在Maven1.0中，你可能会添加一些preGoal到maven.xml并且在project.properties中添加一些条目。这里有些变化。 比如，我们将会配置java编译器能够编译jdk 5.0的代码，只需在你的POM中如下配置即可：12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.5&lt;/source&gt; &lt;target&gt;1.5&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 你会注意所有的Maven插件都在某种程度上类似依赖，插件会自动的下载和使用，而且是一个确定的版本。configuration元素会将给定的参数应用到每个目标。在以上的案例中，编译插件被作为构建过程的一部分，也可以在过程中添加新的目标并配置指定的目标。想了解更多的信息，请看生命周期构建简介想查看什么配置适合一个插件，你可以看插件列表并导航到你在使用的插件和目标。对于怎样配置插件的合适参数，可以查看插件配置指南 我如何将资源添加到jar文件当中？另外一个很常用的案例是不需要做任何POM改变，可以将资源我文件打包到Jar文件当中。对于这个功能，Maven需要依赖标准的目录结构,意思是利用标准的Maven约定将资源放在约定的目录结构，你可以将资源打包到jar文件。看下边的例子，我们可以将想打包的资源文件放在目录${basedir}/src/main/resources。这个简单的规则是说:任何在{basedir}/src/main/resources目录下的目录或文件都会打包到你的jar文件中，而且目录结构也是一样的，基目录的jar文件的根目录。123456789101112131415161718my-app|-- pom.xml`-- src |-- main | |-- java | | `-- com | | `-- mycompany | | `-- app | | `-- App.java | `-- resources | `-- META-INF | `-- application.properties `-- test `-- java `-- com `-- mycompany `-- app `-- AppTest.java 在打包的jar文件中会有一个META-INF目录中有文件appllication.properties。如果你解包jar文件，你可以看到类似如下：123456789101112|-- META-INF| |-- MANIFEST.MF| |-- application.properties| `-- maven| `-- com.mycompany.app| `-- my-app| |-- pom.properties| `-- pom.xml`-- com `-- mycompany `-- app `-- App.class 你可以看到${basedir}/src/main/resources可以在jar文件的根目录下找到，并且在META-INF目录下可以找到application.properties。你同样会注意到一些其他的文件比如META-INF/MANIFEST.MF，pom.xml和pom.properties，这些事Maven默认生成的文件。你可以创建你自己的manifest,如果你不创建，Maven会默认创建一个(你同样可以改变默认的manifest，我们将会在一会说到这个)。pom.xml和pom.properties文件被打包到jar中，因此每个artifact都是独立的，如果你需要的话，你可以利用你自己应用的元数据。一个简单的应用就是可以恢复你应用的版本号。配置文件POM需要你利用一些Maven工具，但是properties可以利用java api，比如：12345#Generated by Maven#Tue Oct 04 15:43:21 GMT-05:00 2005version=1.0-SNAPSHOTgroupId=com.mycompany.appartifactId=my-app 为将资源文件为你的单元测试加载到类路径下，你需要遵循与你添加资源文件到jar中同样的模式，这是你应该拥有一个项目目录结构类似下边：1234567891011121314151617181920my-app|-- pom.xml`-- src |-- main | |-- java | | `-- com | | `-- mycompany | | `-- app | | `-- App.java | `-- resources | `-- META-INF | |-- application.properties `-- test |-- java | `-- com | `-- mycompany | `-- app | `-- AppTest.java `-- resources `-- test.properties 在一个单元测试中你可以利用一小段代码如下去访问需要的资源文件：12345...// Retrieve resourceInputStream is = getClass().getResourceAsStream( &quot;/test.properties&quot; );// Do something with the resource... 我如何过滤资源文件？有时候资源文件需要包含一个值，这个值只能在构建时期使用。为了完成这个功能，利用${&lt;propertyname&gt;}就可以将这个值带入你的资源文件。这个属性可以是你在pom.xml中定义的一个值，用户的setting.xml中的一个值，外部properties文件中的一个值，或者是一个系统属性。为了在复制时利用Maven过滤资源，简单的设置filtering为真即可：1234567891011121314151617181920212223242526272829303132&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;Maven Quick Start Archetype&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 你会注意到我们不得不增加build,resources,resource元素，此外我们不得不明确声明资源文件的位置是src/mai/resources目录。左右的这些信息都是默认提供的，但是因为默认的filtering是false的，我们不得不增加这些信息到我们的pom.xml,为了去重写默认值并且将filtering设置为true。为了引用你在pom.xml中定义的属性，属性名称利用xml元素名称去定义值，pom运行将项目元素作为一个别名，因此${project.version}指的是项目的名称，${project.version}指的是你项目的版本，${project.build.finalName}指的是在项目打包时生成的文件的最终的名称等等。注意一些POM元素拥有默认值，因此不需要明确的在pom.xml中定义。同样，用户的setting.xml中的值可以利用一settings开头的属性名来引用(比如,${settings.localRepository}指的是用户的本地路径)。继续我们的例子，让我们在application.properties中增加两个属性(这个文件我们放到src/main/resources).当资源文件被过滤后，这个文件中的值将会被应用(过滤可以看作扫描)：123# application.propertiesapplication.name=$&#123;project.name&#125;application.version=$&#123;project.version&#125; 到这里，你可以执行如下的命令(process-resources是构建生命周期阶段资源的复制和筛选)：1mvn process-resources application.properties文件在target/classes就像如下：123# application.propertiesapplication.name=Maven Quick Start Archetypeapplication.version=1.0-SNAPSHOT 为了引用定义在外部文件中的属性，你所做的事需要增加一个外部文件的引用到你的pom.xml文件中。首先，让我们创建外部属性文件src/main/filters/filter.properties:12# filter.propertiesmy.filter.value=hello! 接着我们将在pom.xml中引用这个文件：1234567891011121314151617181920212223242526272829303132333435&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;Maven Quick Start Archetype&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;filters&gt; &lt;filter&gt;src/main/filters/filter.properties&lt;/filter&gt; &lt;/filters&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 接着，如我我们可以在application.properties中引用这个属性：1234# application.propertiesapplication.name=$&#123;project.name&#125;application.version=$&#123;project.version&#125;message=$&#123;my.filter.value&#125; 下一步执行mvn process-resources命令将会把我们的新属性值放进application.properties。除了定义my.filter.value在外部文件，你也可以定义其在pom文件中的properties小结，你可以达到相同的效果：123456789101112131415161718192021222324252627282930313233343536&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;Maven Quick Start Archetype&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; &lt;properties&gt; &lt;my.filter.value&gt;hello&lt;/my.filter.value&gt; &lt;/properties&gt;&lt;/project&gt; 过滤资源同样可以获取系统属性；java内建的系统属性(比如java.version或者user.home)或者利用java -D 参数定义在命令行的属性。继续我们的例子，让我们改变application.properties文件像如下：123# application.propertiesjava.version=$&#123;java.version&#125;command.line.prop=$&#123;command.line.prop&#125; 现在，当我们执行如下的命令(注意定义在命令行的command.line.prop的属性)，application.properties文件将会包含属性系统属性的值.1mvn process-resources &quot;-Dcommand.line.prop=hello again&quot; 我如何使用外部的依赖？在之前的例子中，你可能已经注意有一个dependencies元素。实际上你一直在使用一个外部的依赖，但是现在我们讨论一些其工作的细节。想深入了解，请查看依赖机制介绍dependencies小结列出了所有在项目构建过程(无论是变异期、测试期、运行期或者其他)中需要的外部依赖。现在我们的项目只依赖JUnit(为了清晰，我将所有的关于资源的东西都提取出来):1234567891011121314151617181920212223&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;Maven Quick Start Archetype&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 对于每个外部一拉，你需要定义至少四个东西：groupId,artifactId,version和scope,groupId,artifactId和version和上边介绍的pom.xml是一样的。scope元素表明你的项目怎样使用此依赖，值可以是compile,test和runtime。要了解更多的信息，你可以指定一个依赖，并查看项目描述符参考根据这个依赖信息，Maven能够在构建项目是引用依赖Maven从哪里引用依赖呢？Maven会从你的本地仓库中寻找所有的依赖。在之前的章节，我们将artifact(my-app-1.0-SNAPSHOT.jar)安装到了本地仓库.一旦被安装到了本地仓库，另外一个项目也可以引用这个jar文件作为依赖，只需像之前那样讲依赖信息添加到pom.xml文件中就可以了:1234567891011121314151617&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-other-app&lt;/artifactId&gt; ... &lt;dependencies&gt; ... &lt;dependency&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 假如依赖在其他地方使用呢？他们怎样来访问我的本地仓库呢？当一个项目引用依赖在本地仓库不可得是，Maven将会从远程仓库下载依赖到本地仓库。你可能注意到maven下载了许多东西在你勾线你的第一个项目的时候(折现下载的依赖是一些用于构建项目的插件)。默认远程仓库是http://repo.maven.apache.org/maven2/。你同样可以建立自己的远程仓库(可能是你公司的中央仓库)用于替换默认的远程仓库，或者增加一个。了解更多关于仓库的信息你可以引用仓库介绍。让我们添加另外一个依赖到我们的项目。现在我们增加以下日志到代码并且需要增加log4j作为一个依赖。首先我们需要知道log4j的groupId,artifactId以及version等信息。我们可以浏览ibiblio找到这些，或者利用google搜索site:www.ibiblio.org maven2 log4j。搜索会给你展示一个目录/maven2/log4j/log4j或者/pub/packages/maven2/log4j/log4j。在这个目录下有一个文件叫作maven-metadata.xml。这里是log4j的maven-meatdata.xml：123456789101112131415161718&lt;metadata&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;versioning&gt; &lt;versions&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;version&gt;1.2.4&lt;/version&gt; &lt;version&gt;1.2.5&lt;/version&gt; &lt;version&gt;1.2.6&lt;/version&gt; &lt;version&gt;1.2.7&lt;/version&gt; &lt;version&gt;1.2.8&lt;/version&gt; &lt;version&gt;1.2.11&lt;/version&gt; &lt;version&gt;1.2.9&lt;/version&gt; &lt;version&gt;1.2.12&lt;/version&gt; &lt;/versions&gt; &lt;/versioning&gt;&lt;/metadata&gt; 从这个文件里，我们可以看到groupId为log4j并且artifactId为log4j。我们有不多的版本可以进行选择；现在我们用罪行的版本,1.2.12(一些maven-metadata.xml文件可能指定哪个版本是最新的发布版本)。在目录下我们还可以看到每个版本的log4j库。在里边，我们可以看到jar文件(比如log4j-1.2.12.jar)和一个pom文件(这个是依赖的pom文件，表明它拥有的更多的依赖和其他信息)以及另外一个maven-metadata.xml文件。这里还有一个md5文件包含这些文件的MD5哈希值。你可以用这个去验证一个库或者知道你现在正在使用的库的版本号。现在我们知道我们需要的信息，我们可以吧依赖添加到我们的pom.xml文件中。1234567891011121314151617181920212223242526272829&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;Maven Quick Start Archetype&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.12&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 我如何发布jar到远程仓库？对于将jar文件发布到外部仓库，你应该在pom.xml中配置url并且在settings.xml中配置连接到仓库的验证信息。这里是个例子，用scp和用户名/密码验证：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;Maven Quick Start Archetype&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.codehaus.plexus&lt;/groupId&gt; &lt;artifactId&gt;plexus-utils&lt;/artifactId&gt; &lt;version&gt;1.0.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;filters&gt; &lt;filter&gt;src/main/filters/filters.properties&lt;/filter&gt; &lt;/filters&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;mycompany-repository&lt;/id&gt; &lt;name&gt;MyCompany Repository&lt;/name&gt; &lt;url&gt;scp://repository.mycompany.com/repository/maven2&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt;&lt;/project&gt; 12345678910111213141516&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; ... &lt;servers&gt; &lt;server&gt; &lt;id&gt;mycompany-repository&lt;/id&gt; &lt;username&gt;jvanzyl&lt;/username&gt; &lt;!-- Default value is ~/.ssh/id_dsa --&gt; &lt;privateKey&gt;/path/to/identity&lt;/privateKey&gt; (default is ~/.ssh/id_dsa) &lt;passphrase&gt;my_key_passphrase&lt;/passphrase&gt; &lt;/server&gt; &lt;/servers&gt; ...&lt;/settings&gt; 现在如果你连接到了匿名登录的openssh ssh服务器，你每次都需要输入你的用户名和密码去验证(尽管你可以利用另外一个ssh客户端去登录)。这种情况你可以利用公钥去登录验证。假如在settings.xml中有密码这种情况应该注意，了解更多信息，请看密码加密 我如何创建帮助文档？在创建你的帮助文档之前，你可以利用archetype机制来为你的项目生成一个网站，利用如下命令：12345mvn archetype:generate \\ -DarchetypeGroupId=org.apache.maven.archetypes \\ -DarchetypeArtifactId=maven-archetype-site \\ -DgroupId=com.mycompany.app \\ -DartifactId=my-app-site 现在你可以到创建站点指南去学习如何为你的项目创建帮助文档。 我如何构建其他类型的项目？注意生命周期适用于任何项目类型。比如，回到基本目录我们可以创建一个简单的web应用：12345mvn archetype:generate \\ -DarchetypeGroupId=org.apache.maven.archetypes \\ -DarchetypeArtifactId=maven-archetype-webapp \\ -DgroupId=com.mycompany.app \\ -DartifactId=my-webapp 注意这些都必须位于同一行。这将会创建一个目录叫作my-webapp包含如下的项目描述：123456789101112131415161718192021222324&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-webapp&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;my-webapp&lt;/finalName&gt; &lt;/build&gt;&lt;/project&gt; 注意&lt;packaging&gt;元素,这个告诉maven打包类型为war，进入webapp的项目目录并且尝试：1mvn clean package 你将会看到target/my-webapp.war被创建，到目前为止，所有的正常步骤都被执行。 我如何同时构建多个项目？这个概念是说利用Maven构建多个模块。在这节，我们将会展示如何同时构建上述的war包括先前的jar。首先我们需要一个父pom.xml文件在另外两个的上层目录，例如：1234567891011+- pom.xml+- my-app| +- pom.xml| +- src| +- main| +- java+- my-webapp| +- pom.xml| +- src| +- main| +- webapp 这个pom文件你将会创建包含如下的：12345678910111213141516&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;my-app&lt;/module&gt; &lt;module&gt;my-webapp&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; jar需要依赖webapp，因此我们向my-webapp/pom.xml添加如下：123456789... &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; ... &lt;/dependencies&gt; 接着向另外子目录下的pom.xml文件中添加&lt;parent&gt;标签：12345678910&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; ... 现在在顶层目录尝试运行：1mvn clean install war文件将会被创建在my-webapp/target/my-webapp.war中，同样jar也会被创建：12345678910111213$ jar tvf my-webapp/target/my-webapp-1.0-SNAPSHOT.war 0 Fri Jun 24 10:59:56 EST 2005 META-INF/ 222 Fri Jun 24 10:59:54 EST 2005 META-INF/MANIFEST.MF 0 Fri Jun 24 10:59:56 EST 2005 META-INF/maven/ 0 Fri Jun 24 10:59:56 EST 2005 META-INF/maven/com.mycompany.app/ 0 Fri Jun 24 10:59:56 EST 2005 META-INF/maven/com.mycompany.app/my-webapp/3239 Fri Jun 24 10:59:56 EST 2005 META-INF/maven/com.mycompany.app/my-webapp/pom.xml 0 Fri Jun 24 10:59:56 EST 2005 WEB-INF/ 215 Fri Jun 24 10:59:56 EST 2005 WEB-INF/web.xml 123 Fri Jun 24 10:59:56 EST 2005 META-INF/maven/com.mycompany.app/my-webapp/pom.properties 52 Fri Jun 24 10:59:56 EST 2005 index.jsp 0 Fri Jun 24 10:59:56 EST 2005 WEB-INF/lib/2713 Fri Jun 24 10:59:56 EST 2005 WEB-INF/lib/my-app-1.0-SNAPSHOT.jar 这个是怎么创建的？首先父pom创建(称作app),有一个packaging和一系列modules定义。这个告诉Maven在项目集合上去运行操作，而不是当前这个(重写这个行为，你可以利用--non-recursive命令)接着，我们告诉war需要my-app的jar.这个做了一些事情：可以是其在类路径上，war中的其他代码可以找到，保证jar的构建总是先于war的，并且表明war插件将jar包含到它的库目录下。你可能注意到junit-4.11.jar是一个依赖，但是并没有在war中结束(与生命周期有关，因此用结束来修饰)。原因是&lt;scope&gt;test&lt;/scope&gt;原色，这个仅用来测试，并且不会包含在web应用当中。最后一步是添加parent定义，这个不同于extend元素(maven 1.0):这个保证POM总是可以定位到，即使项目与其双亲是分布式的，以查找仓库的方式。不想Maven1.0，不需要你运行install去成功执行这些步骤，你可以运行package，可以在target目录中生成，而不会是本地仓库。你可能喜欢再次生成你的IDEA工作区在顶层目录…1mvn idea:idea","categories":[{"name":"Java","slug":"Java","permalink":"peachey.blog/categories/Java/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"peachey.blog/tags/Maven/"}]}]}